{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Day 13 Homework3_qlearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lagom-QB/M12/blob/master/Day%2013%20Homework3_qlearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2AK5M3ML8ae",
        "colab_type": "text"
      },
      "source": [
        "## Homework 3: model free learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIDIgDV2L8ai",
        "colab_type": "text"
      },
      "source": [
        "## Part I: On-policy learning and SARSA (3 points)\n",
        "\n",
        "_This notebook builds upon `day10` practice(`qlearning_practice.ipynb`), or to be exact, generating qlearning.py._\n",
        "\n",
        "The policy we're gonna use is epsilon-greedy policy, where agent takes optimal action with probability $(1-\\epsilon)$, otherwise samples action at random. Note that agent __can__ occasionally sample optimal action during random sampling by pure chance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MW5UnYvL8al",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "329925ea-2d4f-4f02-d89d-a76cdb5850a4"
      },
      "source": [
        "# In google collab, uncomment this:\n",
        "!wget https://bit.ly/2FMJP5K -q -O setup.py\n",
        "!bash setup.py 2>&1 1>stdout.log | tee stderr.log\n",
        "\n",
        "!pip install pyglet==1.4.9\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# If you are running locally, just ignore it\n",
        "import os\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-25 20:37:32--  https://raw.githubusercontent.com/yandexdataschool/Practical_DL/fall18/xvfb\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 640 [text/plain]\n",
            "Saving to: ‘../xvfb’\n",
            "\n",
            "     0K                                                       100% 51.2M=0s\n",
            "\n",
            "2020-06-25 20:37:33 (51.2 MB/s) - ‘../xvfb’ saved [640/640]\n",
            "\n",
            "ERROR: gym 0.17.2 has requirement pyglet<=1.5.0,>=1.4.0, but you'll have pyglet 1.2.4 which is incompatible.\n",
            "Collecting pyglet==1.4.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/a7/b609f0930b6e601b8f2f65636e5f652b5094e5faba0e44109e2a7edd7c3e/pyglet-1.4.9-py2.py3-none-any.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 12.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet==1.4.9) (0.16.0)\n",
            "Installing collected packages: pyglet\n",
            "  Found existing installation: pyglet 1.2.4\n",
            "    Uninstalling pyglet-1.2.4:\n",
            "      Successfully uninstalled pyglet-1.2.4\n",
            "Successfully installed pyglet-1.4.9\n",
            "Starting virtual X frame buffer: Xvfb.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxZAC7YSL8a4",
        "colab_type": "text"
      },
      "source": [
        "Now you can use code, generated from seminar `seminar_qlearning.ipynb`. Or just copy&paste it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vykMRW_PL8a8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 29
        },
        "outputId": "4c667558-7350-45c0-94db-3ef4018dd6bf"
      },
      "source": [
        "%%writefile qlearning.py\n",
        "from collections import defaultdict\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, alpha, epsilon, discount, get_legal_actions):\n",
        "        \"\"\"\n",
        "        Q-Learning Agent\n",
        "        based on https://inst.eecs.berkeley.edu/~cs188/sp19/projects.html\n",
        "        Instance variables you have access to\n",
        "          - self.epsilon (exploration prob)\n",
        "          - self.alpha (learning rate)\n",
        "          - self.discount (discount rate aka gamma)\n",
        "\n",
        "        Functions you should use\n",
        "          - self.get_legal_actions(state) {state, hashable -> list of actions, each is hashable}\n",
        "            which returns legal actions for a state\n",
        "          - self.get_qvalue(state,action)\n",
        "            which returns Q(state,action)\n",
        "          - self.set_qvalue(state,action,value)\n",
        "            which sets Q(state,action) := value\n",
        "\n",
        "        !!!Important!!!\n",
        "        Note: please avoid using self._qValues directly. \n",
        "            There's a special self.get_qvalue/set_qvalue for that.\n",
        "        \"\"\"\n",
        "\n",
        "        self.get_legal_actions = get_legal_actions\n",
        "        self._qvalues = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "        self.alpha = alpha\n",
        "        self.epsilon = epsilon\n",
        "        self.discount = discount\n",
        "\n",
        "    def get_qvalue(self, state, action):\n",
        "        \"\"\" Returns Q(state,action) \"\"\"\n",
        "        return self._qvalues[state][action]\n",
        "\n",
        "    def set_qvalue(self, state, action, value):\n",
        "        \"\"\" Sets the Qvalue for [state,action] to the given value \"\"\"\n",
        "        self._qvalues[state][action] = value\n",
        "\n",
        "    #---------------------START OF YOUR CODE---------------------#\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\"\n",
        "        Compute your agent's estimate of V(s) using current q-values\n",
        "        V(s) = max_over_action Q(state,action) over possible actions.\n",
        "        Note: please take into account that q-values can be negative.\n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return 0.0\n",
        "        if len(possible_actions) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        value = max([self.get_qvalue(state, action) for action in possible_actions])\n",
        "        return value\n",
        "\n",
        "    def update(self, state, action, reward, next_state):\n",
        "        \"\"\"\n",
        "        You should do your Q-Value update here:\n",
        "           Q(s,a) := (1 - alpha) * Q(s,a) + alpha * (r + gamma * V(s'))\n",
        "        \"\"\"\n",
        "\n",
        "        # agent parameters\n",
        "        gamma = self.discount\n",
        "        learning_rate = self.alpha\n",
        "\n",
        "        reference_qvalue = reward + gamma * self.get_value(next_state)\n",
        "        new_qvalue = (1 - learning_rate) * self.get_qvalue(state, action) + learning_rate * reference_qvalue\n",
        "        self.set_qvalue(state, action, new_qvalue )\n",
        "\n",
        "    def get_best_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the best action to take in a state (using current q-values). \n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        all_action_values = np.array([self.get_qvalue(state, action) for action in possible_actions])\n",
        "        best_action = np.argmax(all_action_values) \n",
        "        return best_action\n",
        "\n",
        "    def get_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the action to take in the current state, including exploration.  \n",
        "        With probability self.epsilon, we should take a random action.\n",
        "            otherwise - the best policy action (self.getPolicy).\n",
        "\n",
        "        Note: To pick randomly from a list, use random.choice(list). \n",
        "              To pick True or False with a given probablity, generate uniform number in [0, 1]\n",
        "              and compare it with your probability\n",
        "        \"\"\"\n",
        "\n",
        "        # Pick Action\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "        action = None\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        # agent parameters:\n",
        "        epsilon = self.epsilon\n",
        "\n",
        "        flip_coin = np.random.uniform(0, 1)\n",
        "        \n",
        "        if flip_coin > epsilon:\n",
        "            chosen_action = self.get_best_action(state)\n",
        "        else:\n",
        "            chosen_action = np.random.choice(possible_actions)\n",
        "            \n",
        "        return chosen_action"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing qlearning.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qErX7_AHM738",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softMax(x):\n",
        "    return np.exp(x)/np.sum(np.exp(x))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJo1rPR8L8bI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from qlearning import QLearningAgent\n",
        "\n",
        "\n",
        "class EVSarsaAgent(QLearningAgent):\n",
        "    \"\"\" \n",
        "    An agent that changes some of q-learning functions to implement Expected Value SARSA. \n",
        "    Note: this demo assumes that your implementation of QLearningAgent.update uses get_value(next_state).\n",
        "    If it doesn't, please add\n",
        "        def update(self, state, action, reward, next_state):\n",
        "            and implement it for Expected Value SARSA's V(s')\n",
        "    \"\"\"\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\" \n",
        "        Returns Vpi for current state under epsilon-greedy policy:\n",
        "          V_{pi}(s) = sum _{over a_i} {pi(a_i | s) * Q(s, a_i)}\n",
        "\n",
        "        Hint: all other methods from QLearningAgent are still accessible.\n",
        "        \"\"\"\n",
        "        epsilon = self.epsilon\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return 0.0\n",
        "        if len(possible_actions) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        flip = np.random.uniform(0, 1)\n",
        "        if flip > epsilon:\n",
        "            all_qvalues = np.array([self.get_qvalue(state, action) for action in possible_actions])\n",
        "            p = softMax(all_qvalues)\n",
        "            state_value = sum(map(lambda pi_q: pi_q[0] * pi_q[1], zip(p, all_qvalues)))\n",
        "        else:\n",
        "            state_value = self.get_qvalue(state, np.random.choice(possible_actions))\n",
        "\n",
        "        return state_value"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3I9SFUiL8bS",
        "colab_type": "text"
      },
      "source": [
        "### Cliff World\n",
        "\n",
        "Let's now see how our algorithm compares against q-learning in case where we force agent to explore all the time.\n",
        "\n",
        "![](https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/cliffworld.png \"image by cs188\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTq30UBOL8bT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "7f19b10f-ebe8-487b-d432-9188ba22ec49"
      },
      "source": [
        "import gym\n",
        "import gym.envs.toy_text\n",
        "env = gym.envs.toy_text.CliffWalkingEnv()\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "print(env.__doc__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "    This is a simple implementation of the Gridworld Cliff\n",
            "    reinforcement learning task.\n",
            "\n",
            "    Adapted from Example 6.6 (page 106) from Reinforcement Learning: An Introduction\n",
            "    by Sutton and Barto:\n",
            "    http://incompleteideas.net/book/bookdraft2018jan1.pdf\n",
            "\n",
            "    With inspiration from:\n",
            "    https://github.com/dennybritz/reinforcement-learning/blob/master/lib/envs/cliff_walking.py\n",
            "\n",
            "    The board is a 4x12 matrix, with (using Numpy matrix indexing):\n",
            "        [3, 0] as the start at bottom-left\n",
            "        [3, 11] as the goal at bottom-right\n",
            "        [3, 1..10] as the cliff at bottom-center\n",
            "\n",
            "    Each time step incurs -1 reward, and stepping into the cliff incurs -100 reward\n",
            "    and a reset to the start. An episode terminates when the agent reaches the goal.\n",
            "    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZGveZLyL8bd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "a7f491bf-f0fa-42c6-ac31-5a47e5cf63c2"
      },
      "source": [
        "# Our cliffworld has one difference from what's on the image: there is no wall.\n",
        "# Agent can choose to go as close to the cliff as it wishes. x:start, T:exit, C:cliff, o: flat ground\n",
        "env.render()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "x  C  C  C  C  C  C  C  C  C  C  T\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g931mVZbL8bo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def play_and_train(env, agent, t_max=10**4):\n",
        "    \"\"\"This function should \n",
        "    - run a full game, actions given by agent.getAction(s)\n",
        "    - train agent using agent.update(...) whenever possible\n",
        "    - return total reward\"\"\"\n",
        "    total_reward = 0.0\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "        a = agent.get_action(s)\n",
        "\n",
        "        next_s, r, done, _ = env.step(a)\n",
        "        agent.update(s, a, r, next_s)\n",
        "\n",
        "        s = next_s\n",
        "        total_reward += r\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    return total_reward"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XuhFiJLL8bw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from qlearning import QLearningAgent\n",
        "\n",
        "agent_sarsa = EVSarsaAgent(alpha=0.25, epsilon=0.2, discount=0.99,\n",
        "                           get_legal_actions=lambda s: range(n_actions))\n",
        "\n",
        "agent_ql = QLearningAgent(alpha=0.25, epsilon=0.2, discount=0.99,\n",
        "                          get_legal_actions=lambda s: range(n_actions))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2Tdgv4iL8b4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "47d605a3-8a0f-42bf-f3dc-3d46d08ea401"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from pandas import DataFrame\n",
        "\n",
        "\n",
        "def moving_average(x, span=100): return DataFrame(\n",
        "    {'x': np.asarray(x)}).x.ewm(span=span).mean().values\n",
        "\n",
        "\n",
        "rewards_sarsa, rewards_ql = [], []\n",
        "\n",
        "for i in range(5000):\n",
        "    rewards_sarsa.append(play_and_train(env, agent_sarsa))\n",
        "    rewards_ql.append(play_and_train(env, agent_ql))\n",
        "    # Note: agent.epsilon stays constant\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        clear_output(True)\n",
        "        print('EVSARSA mean reward =', np.mean(rewards_sarsa[-100:]))\n",
        "        print('QLEARNING mean reward =', np.mean(rewards_ql[-100:]))\n",
        "        plt.title(\"epsilon = %s\" % agent_ql.epsilon)\n",
        "        plt.plot(moving_average(rewards_sarsa), label='ev_sarsa')\n",
        "        plt.plot(moving_average(rewards_ql), label='qlearning')\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        plt.ylim(-500, 0)\n",
        "        plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EVSARSA mean reward = -33.25\n",
            "QLEARNING mean reward = -82.18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BouA0-LoL8cB",
        "colab_type": "text"
      },
      "source": [
        "Let's now see what did the algorithms learn by visualizing their actions at every state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZqB4dt0L8cC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_policy(env, agent):\n",
        "    \"\"\" Prints CliffWalkingEnv policy with arrows. Hard-coded. \"\"\"\n",
        "    n_rows, n_cols = env._cliff.shape\n",
        "\n",
        "    actions = '^>v<'\n",
        "\n",
        "    for yi in range(n_rows):\n",
        "        for xi in range(n_cols):\n",
        "            if env._cliff[yi, xi]:\n",
        "                print(\" C \", end='')\n",
        "            elif (yi * n_cols + xi) == env.start_state_index:\n",
        "                print(\" X \", end='')\n",
        "            elif (yi * n_cols + xi) == n_rows * n_cols - 1:\n",
        "                print(\" T \", end='')\n",
        "            else:\n",
        "                print(\" %s \" %\n",
        "                      actions[agent.get_best_action(yi * n_cols + xi)], end='')\n",
        "        print()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb5mTJXFL8cK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "87c5d101-bb95-485c-cb23-6e8f1c086b8d"
      },
      "source": [
        "print(\"Q-Learning\")\n",
        "draw_policy(env, agent_ql)\n",
        "\n",
        "print(\"SARSA\")\n",
        "draw_policy(env, agent_sarsa)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q-Learning\n",
            " >  >  v  v  v  >  >  v  >  v  >  v \n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " X  C  C  C  C  C  C  C  C  C  C  T \n",
            "SARSA\n",
            " >  >  >  >  >  >  ^  >  >  >  >  v \n",
            " ^  ^  >  ^  ^  ^  ^  ^  ^  >  >  v \n",
            " ^  ^  <  ^  ^  ^  ^  ^  >  >  >  v \n",
            " X  C  C  C  C  C  C  C  C  C  C  T \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0OzOb0aL8cT",
        "colab_type": "text"
      },
      "source": [
        "### More on SARSA\n",
        "\n",
        "Here are some of the things you can do if you feel like it:\n",
        "\n",
        "* Play with epsilon. See learned how policies change if you set epsilon to higher/lower values (e.g. 0.75).\n",
        "* Expected Value SASRSA for softmax policy __(2pts)__:\n",
        "$$ \\pi(a_i|s) = softmax({Q(s,a_i) \\over \\tau}) = {e ^ {Q(s,a_i)/ \\tau}  \\over {\\sum_{a_j}  e ^{Q(s,a_j) / \\tau }}} $$\n",
        "* Implement N-step algorithms and TD($\\lambda$): see [Sutton's book](http://incompleteideas.net/book/bookdraft2018jan1.pdf) chapter 7 and chapter 12.\n",
        "* Use those algorithms to train on CartPole in previous / next assignment for this week."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPjBQDOaL8cU",
        "colab_type": "text"
      },
      "source": [
        "## Part II: experience replay (4 points)\n",
        "\n",
        "There's a powerful technique that you can use to improve sample efficiency for off-policy algorithms: [spoiler] Experience replay :)\n",
        "\n",
        "The catch is that you can train Q-learning and EV-SARSA on `<s,a,r,s'>` tuples even if they aren't sampled under current agent's policy. So here's what we're gonna do:\n",
        "\n",
        "<img src=https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/exp_replay.png width=480>\n",
        "\n",
        "#### Training with experience replay\n",
        "1. Play game, sample `<s,a,r,s'>`.\n",
        "2. Update q-values based on `<s,a,r,s'>`.\n",
        "3. Store `<s,a,r,s'>` transition in a buffer. \n",
        " 3. If buffer is full, delete earliest data.\n",
        "4. Sample K such transitions from that buffer and update q-values based on them.\n",
        "\n",
        "\n",
        "To enable such training, first we must implement a memory structure that would act like such a buffer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtObsvUfL8cV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 40
        },
        "outputId": "c9a8921b-d1bb-4a6a-d148-8d22ea344269"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uZvhMVVL8cf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "\n",
        "class ReplayBuffer(object):\n",
        "    def __init__(self, size):\n",
        "        \"\"\"\n",
        "        Create Replay buffer.\n",
        "        Parameters\n",
        "        ----------\n",
        "        size: int\n",
        "            Max number of transitions to store in the buffer. When the buffer\n",
        "            overflows the old memories are dropped.\n",
        "\n",
        "        Note: for this assignment you can pick any data structure you want.\n",
        "              If you want to keep it simple, you can store a list of tuples of (s, a, r, s') in self._storage\n",
        "              However you may find out there are faster and/or more memory-efficient ways to do so.\n",
        "        \"\"\"\n",
        "        self._storage = []\n",
        "        self._maxsize = size\n",
        "        self.nxt = 0\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._storage)\n",
        "\n",
        "    def add(self, obs_t, action, reward, obs_tp1, done):\n",
        "        '''\n",
        "        Make sure, _storage will not exceed _maxsize. \n",
        "        Make sure, FIFO rule is being followed: the oldest examples has to be removed earlier\n",
        "        '''\n",
        "        data = (obs_t, action, reward, obs_tp1, done)\n",
        "\n",
        "        # add data to storage\n",
        "        if self.nxt >= len(self._storage):\n",
        "            self._storage.append(data)\n",
        "        else:\n",
        "            self._storage[self.nxt] = data\n",
        "        self.nxt = (self.nxt + 1) % self._maxsize\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        \"\"\"Sample a batch of experiences.\n",
        "        Parameters\n",
        "        ----------\n",
        "        batch_size: int\n",
        "            How many transitions to sample.\n",
        "        Returns\n",
        "        -------\n",
        "        obs_batch: np.array\n",
        "            batch of observations\n",
        "        act_batch: np.array\n",
        "            batch of actions executed given obs_batch\n",
        "        rew_batch: np.array\n",
        "            rewards received as results of executing act_batch\n",
        "        next_obs_batch: np.array\n",
        "            next set of observations seen after executing act_batch\n",
        "        done_mask: np.array\n",
        "            done_mask[i] = 1 if executing act_batch[i] resulted in\n",
        "            the end of an episode and 0 otherwise.\n",
        "        \"\"\"\n",
        "        idxes = [random.randint(0, len(self._storage) - 1) for _ in range(batch_size)]          #<randomly generate batch_size integers to be used as indexes of samples >\n",
        "        obses_t, actions, rewards, obses_tp1, dones = [], [], [], [], []\n",
        "\n",
        "        # collect <s,a,r,s',done> for each index\n",
        "        for i in idxes:\n",
        "            data = self._storage[i]\n",
        "            obs_t, action, reward, obs_tp1, done = data\n",
        "            obses_t.append(np.array(obs_t, copy=False))\n",
        "            actions.append(np.array(action, copy=False))\n",
        "            rewards.append(reward)\n",
        "            obses_tp1.append(np.array(obs_tp1, copy=False))\n",
        "            dones.append(done)\n",
        "\n",
        "        return np.array(obses_t), np.array(actions), np.array(rewards), np.array(obses_tp1), np.array(dones)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dUDe7fJL8cn",
        "colab_type": "text"
      },
      "source": [
        "Some tests to make sure your buffer works right"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP6sWSURL8co",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 29
        },
        "outputId": "4e51c83b-fca2-4553-ecaa-e3a9d2188365"
      },
      "source": [
        "def obj2arrays(obj):\n",
        "    for x in obj:\n",
        "        yield np.array([x])\n",
        "\n",
        "def obj2sampled(obj):\n",
        "    return tuple(obj2arrays(obj))\n",
        "\n",
        "replay = ReplayBuffer(2)\n",
        "obj1 = (0, 1, 2, 3, True)\n",
        "obj2 = (4, 5, 6, 7, False)\n",
        "replay.add(*obj1)\n",
        "assert replay.sample(\n",
        "    1) == obj2sampled(obj1), \"If there's just one object in buffer, it must be retrieved by buf.sample(1)\"\n",
        "replay.add(*obj2)\n",
        "assert len(replay) == 2, \"Please make sure __len__ methods works as intended.\"\n",
        "replay.add(*obj2)\n",
        "assert len(replay) == 2, \"When buffer is at max capacity, replace objects instead of adding new ones.\"\n",
        "assert tuple(np.unique(a) for a in replay.sample(100)) == obj2sampled(obj2)\n",
        "replay.add(*obj1)\n",
        "assert max(len(np.unique(a)) for a in replay.sample(100)) == 2\n",
        "replay.add(*obj1)\n",
        "assert tuple(np.unique(a) for a in replay.sample(100)) == obj2sampled(obj1)\n",
        "print(\"Success!\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Success!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3mWb2AgL8cw",
        "colab_type": "text"
      },
      "source": [
        "Now let's use this buffer to improve training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu8Rw8-1L8cy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "from qlearning import QLearningAgent\n",
        "\n",
        "env = gym.make(\"Taxi-v3\")\n",
        "n_actions = env.action_space.n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkFWU_WmL8c6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def play_and_train_with_replay(env, agent, replay=None,\n",
        "                               t_max=10**4, replay_batch_size=32):\n",
        "    \"\"\"\n",
        "    This function should \n",
        "    - run a full game, actions given by agent.getAction(s)\n",
        "    - train agent using agent.update(...) whenever possible\n",
        "    - return total reward\n",
        "    :param replay: ReplayBuffer where agent can store and sample (s,a,r,s',done) tuples.\n",
        "        If None, do not use experience replay\n",
        "    \"\"\"\n",
        "    total_reward = 0.0\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "        # get agent to pick action given state s\n",
        "        a = agent.get_action(s)\n",
        "\n",
        "        next_s, r, done, _ = env.step(a)\n",
        "\n",
        "        # update agent on current transition. Use agent.update\n",
        "        agent.update(s, a, r, next_s)\n",
        "\n",
        "        if replay is not None:\n",
        "            # store current <s,a,r,s'> transition in buffer\n",
        "            replay.add(obs_t=s, action=a, reward=r, obs_tp1=next_s, done=done)\n",
        "            \n",
        "            # sample replay_batch_size random transitions from replay,\n",
        "            # then update agent on each of them in a loop\n",
        "            \n",
        "            s_, a_, r_, next_s_, done_ = replay.sample(replay_batch_size)\n",
        "\n",
        "            for i in range(replay_batch_size):\n",
        "                agent.update(s, a, r, next_s)\n",
        "        \n",
        "        s = next_s\n",
        "        total_reward += r\n",
        "        \n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    return total_reward"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM9H4ySUL8dA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create two agents: first will use experience replay, second will not.\n",
        "\n",
        "agent_baseline = QLearningAgent(alpha=0.5, epsilon=0.25, discount=0.99,\n",
        "                                get_legal_actions=lambda s: range(n_actions))\n",
        "\n",
        "agent_replay = QLearningAgent(alpha=0.5, epsilon=0.25, discount=0.99,\n",
        "                              get_legal_actions=lambda s: range(n_actions))\n",
        "\n",
        "replay = ReplayBuffer(1000)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u-VK2JfL8dG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "5d2a423c-8b1d-414d-f3f2-bf3e69d3f7ec"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "rewards_replay, rewards_baseline = [], []\n",
        "\n",
        "for i in range(1000):\n",
        "    rewards_replay.append(\n",
        "        play_and_train_with_replay(env, agent_replay, replay))\n",
        "    rewards_baseline.append(play_and_train_with_replay(\n",
        "        env, agent_baseline, replay=None))\n",
        "\n",
        "    agent_replay.epsilon *= 0.99\n",
        "    agent_baseline.epsilon *= 0.99\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        clear_output(True)\n",
        "        print('Baseline : eps =', agent_replay.epsilon,\n",
        "              'mean reward =', np.mean(rewards_baseline[-10:]))\n",
        "        print('ExpReplay: eps =', agent_baseline.epsilon,\n",
        "              'mean reward =', np.mean(rewards_replay[-10:]))\n",
        "        plt.plot(moving_average(rewards_replay), label='exp. replay')\n",
        "        plt.plot(moving_average(rewards_baseline), label='baseline')\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline : eps = 2.9191091959171894e-05 mean reward = 8.0\n",
            "ExpReplay: eps = 2.9191091959171894e-05 mean reward = 7.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqZ3pMnhL8dX",
        "colab_type": "text"
      },
      "source": [
        "#### What to expect:\n",
        "\n",
        "Experience replay, if implemented correctly, will improve algorithm's initial convergence a lot, but it shouldn't affect the final performance.\n",
        "\n",
        "### Outro\n",
        "\n",
        "We will use the code you just wrote extensively in the next week of our course. If you're feeling that you need more examples to understand how experience replay works, try using it for binarized state spaces (CartPole or other __[classic control envs](https://gym.openai.com/envs/#classic_control)__).\n",
        "\n",
        "However, __the code you've written__ for this assignment is already capable of solving many RL problems, and as an added benifit – it is very easy to detach. You can use Q-learning, SARSA and Experience Replay for any RL problems you want to solve – just thow 'em into a file and import the stuff you need."
      ]
    }
  ]
}