{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                    Download and import some packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-2.11.0-py3-none-any.whl (674 kB)\n",
      "\u001b[K     |████████████████████████████████| 674 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/qb/anaconda3/lib/python3.7/site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: filelock in /home/qb/anaconda3/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy in /home/qb/anaconda3/lib/python3.7/site-packages (from transformers) (1.18.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/qb/anaconda3/lib/python3.7/site-packages (from transformers) (4.42.1)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
      "\u001b[K     |████████████████████████████████| 883 kB 18.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2020.6.8-cp37-cp37m-manylinux2010_x86_64.whl (661 kB)\n",
      "\u001b[K     |████████████████████████████████| 661 kB 16.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/qb/anaconda3/lib/python3.7/site-packages (from transformers) (20.1)\n",
      "Collecting tokenizers==0.7.0\n",
      "  Downloading tokenizers-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 8.6 MB/s eta 0:00:01     |███████████████████████▊        | 4.2 MB 8.6 MB/s eta 0:00:01     |███████████████████████████▏    | 4.8 MB 8.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 24.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/qb/anaconda3/lib/python3.7/site-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/qb/anaconda3/lib/python3.7/site-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/qb/anaconda3/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/qb/anaconda3/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: six in /home/qb/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (1.14.0)\n",
      "Requirement already satisfied: click in /home/qb/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /home/qb/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/qb/anaconda3/lib/python3.7/site-packages (from packaging->transformers) (2.4.6)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893259 sha256=498eba5ca496903776cac634d265269ec8f43668588d45bfb9d8767c798bc800\n",
      "  Stored in directory: /home/qb/.cache/pip/wheels/69/09/d1/bf058f7d6fa0ecba2ce7c66be3b8d012beb4bf61a6e0c101c0\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: regex, sacremoses, tokenizers, sentencepiece, transformers\n",
      "Successfully installed regex-2020.6.8 sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            PART ONE: Using BERT for text classification\n",
    "    Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    'https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv',\n",
    "    delimiter='\\t',\n",
    "    header=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1041\n",
       "0     959\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_1 = df[:2000] #Performance issues\n",
    "batch_1[1].value_counts() #1 >> Positive 0 >> Neative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Load Pre-trained BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a12c87bff6d4031a012ee7cfa74a641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d4d019229af46d88345a0aa5b868259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a4d83b81004318969b12cf7093559a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# For DistilBERT: << Smaller faster and uses less memory\n",
    "# model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "## Want BERT instead of distilBERT? \n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        1.Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ Tokenization\n",
    "\n",
    "tokenized = batch_1[0].apply((lambda x: tokenizer.encode(x, add_special_tokens = True)))\n",
    "\n",
    "# --- tokenized >> A list of indexes of varied length sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ Padding\n",
    "\n",
    "max_len = max([len(i) for i in tokenized.values])\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "# --- padded >> An ndarray of sentences of max_len length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- Masking __So BERT ignores the padding when processing\n",
    "\n",
    "attention_mask = np.where(padded != 0,\n",
    "                         1,\n",
    "                         0) \n",
    "# np.where(condition, [x,y] >> Return element chosen from x ,y depending on condition i.e if condition return x else y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- DEEP LEARNING with our model\n",
    "\n",
    "input_idx = torch.tensor(padded)\n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_state = model(input_idx, attention_mask = attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            How does bert do sentence classification?\n",
    "_It adds a token called CLS at the beginning of every sentence_ \\\n",
    "BERT output is 3-dimensional for row, positions in each sequence, number of hidden layers.\\\n",
    "But we need just the CLS column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = last_hidden_state[0][:,0,:].numpy()\n",
    "\n",
    "# --- features >> CLS column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = batch_1[1]\n",
    "\n",
    "# labels >> batch_1 labels(1) column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels =  train_test_split(features,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        2.i. Train Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cls = LogisticRegression()\n",
    "lr_cls.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        2.ii. Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.832"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cls.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier scores: 0.483 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "cls = DummyClassifier()\n",
    "\n",
    "scores = cross_val_score(cls, train_features, train_labels)\n",
    "print(\"Dummy classifier scores: %0.3f (+/- %0.2f)\" %(scores.mean(), scores.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Redo HW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘comments.tsv’ already there; not retrieving.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "try:\n",
    "    data = pd.read_csv('./datasets/comments_small_dataset/comments.tsv', sep='\\t')\n",
    "except FileNotFoundError:\n",
    "    ! wget https://raw.githubusercontent.com/neychev/harbour_dlia2020/master/datasets/comments_small_dataset/comments.tsv -nc\n",
    "    data = pd.read_csv(\"comments.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>should_ban</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Those who're in advantageous positions are th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1</td>\n",
       "      <td>Fartsalot56 says f**k you motherclucker!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>1</td>\n",
       "      <td>Are you a fool? \\n\\nI am sorry, but you seem t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>1</td>\n",
       "      <td>I AM NOT A VANDAL!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>0</td>\n",
       "      <td>Citing sources\\n\\nCheck out the Wikipedia:Citi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     should_ban                                       comment_text\n",
       "50            0  \"Those who're in advantageous positions are th...\n",
       "250           1          Fartsalot56 says f**k you motherclucker!!\n",
       "450           1  Are you a fool? \\n\\nI am sorry, but you seem t...\n",
       "650           1    I AM NOT A VANDAL!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
       "850           0  Citing sources\\n\\nCheck out the Wikipedia:Citi..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = data['comment_text'].values\n",
    "target = data['should_ban'].values\n",
    "data[50::200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "texts_train, texts_test, y_train, y_test = train_test_split(texts, target, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train_tokenized = [tokenizer.encode(x, max_length=512, add_special_tokens=True) for x in texts_train]\n",
    "texts_test_tokenized = [tokenizer.encode(x, max_length=512, add_special_tokens=True) for x in texts_test] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_texts(texts_tokenized):\n",
    "    max_len = 0\n",
    "    for i in texts_tokenized:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "\n",
    "    padded = np.array([i + [0]*(max_len-len(i)) for i in texts_tokenized])\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_train = pad_texts(texts_train_tokenized)\n",
    "padded_test = pad_texts(texts_test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_mask(padded_text):\n",
    "    return np.where(padded_text != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 512)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask_train = attention_mask(padded_train)\n",
    "attention_mask_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 512)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask_test = attention_mask(padded_test)\n",
    "attention_mask_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Move the model to gpu and check if it is in eval mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda: 0') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b08ee66daf4493bb5acb449ac6d704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=23.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "output_train = []\n",
    "batch_size = 22\n",
    "\n",
    "for idx in tqdm.tnrange(0, len(padded_train), batch_size):\n",
    "    batch = torch.tensor(padded_train[idx:idx+batch_size]).to(device)\n",
    "    local_attention_mask = torch.tensor(attention_mask_train[idx:idx+batch_size]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(batch, attention_mask = local_attention_mask)[0][:,0,:].cpu().numpy()\n",
    "        output_train.append(last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f21376a2e19a4a8e8338bf7424eeb4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=23.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_test = []\n",
    "batch_size = 22\n",
    "\n",
    "for idx in tqdm.tnrange(0, len(padded_train), batch_size):\n",
    "    batch = torch.tensor(padded_train[idx:idx+batch_size]).to(device)\n",
    "    local_attention_mask = torch.tensor(attention_mask_train[idx:idx+batch_size]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(batch, attention_mask = local_attention_mask)[0][:,0,:].cpu().numpy()\n",
    "        output_test.append(last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.vstack(output_train)\n",
    "test_features  = np.vstack(output_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.498"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_lr_cls = LogisticRegression()\n",
    "\n",
    "new_lr_cls.fit(train_features, y_train)\n",
    "new_lr_cls.score(test_features, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1521968d50>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAfgUlEQVR4nO3dfXRU1b3/8fcXkoJUFAWsEAyJ5aGE8KQpigJCFQVU0BYpWCsqmrbKtdViheUPbvWuLqSxV2QVq9QfD72sElFr4Vd5WiouvEUeggWEAA0KSkAQKYII8rh/f0xmOkwmyUkyk5k583mtlcWcmT1n9mHgy+Z79v5uc84hIiKpr1GiOyAiIrGhgC4i4hMK6CIiPqGALiLiEwroIiI+kZGoD27VqpXLyclJ1MeLiKSk9evXf+6cax3ttYQF9JycHEpKShL18SIiKcnMPq7qNaVcRER8QgFdRMQnFNBFRHxCAV1ExCcU0EVEfKLGgG5ms8zsMzPbXMXrZmbTzWyHmW0ysyti300REamJlxH6HGBwNa8PATpW/BQCf6h/t0REpLZqnIfunFtpZjnVNBkO/MkF6vCuNrMWZtbGOfdpjPpYL39e8wkLN+xJdDdEJI1df2wx1x5fETr+skUXrn7wjzH/nFgsLMoCdocdl1c8Vymgm1khgVE82dnZdfqw2gboNTv/BcBVuRfX6fNEROrr2uMryDn1EbsyL4/r58QioFuU56LumuGcmwnMBCgoKKjTzhoLN+yh9NMj5LW5wFP7q3IvZnjPLO68qm7/gIiI1EnJbPjg1cBj+wSye9H13jfi+pGxCOjlwGVhx+2AvTE4b5Xy2lzAyz/pE8+PEBGpnw9ehX0fwKXdAj/dRsT9I2MR0BcB48ysGLgKOJws+XMRkYQomQ0f/y+07wtxHpWHqzGgm9l8YADQyszKgf8EMgGccy8Ai4GhwA7gGHBvvDorIpL0SmbD334ReNwAo/JwXma5jK7hdQc8FLMeiYikmvB8+cf/G/j1lmlQ0LDj24SVzxURSTnhgTtcMIi37xv46TaiwYM5KKCLiHgXfqMzXAKDeDgFdBGR2ri0W4Pe6KwNFecSEfEJjdBFRKoTnjePlm5JIhqhi4hUJTgFMXjTs4EWCNWVRugikn6qmq0SKYFTEOtCAV1E0kv4wp/2fatvmySzV7xSQBcR/0uShT/xpoAuIv4TmVJJkoU/8aaALiL+E7kAyMdBPJwCuoj4S4IqHSYDTVsUEX8JplqSeHphvGiELiKpLTJfvu+DwOjc5+mVaDRCF5HUFsyXByX54p940ghdRFJfEhfMakgaoYtI6greABVAAV1EUlUCt3pLVgroIpKagjdCfbjis66UQxeR1BFZyjZNZ7NURSN0EUkd4TNa0ng2S1U0QheR1KIZLVVSQBeR5JZCOwYlmlIuIpLclGbxTCN0EUl+SrN4ohG6iIhPaIQuIsklWrEt5c090QhdRJKLim3VmUboIpI80nhzilhQQBeRxKlq70+NyOtEKRcRSZzI9Er7vqrNUg+eRuhmNhh4DmgMvOScezri9WxgLtCios0E59ziGPdVRPxE6ZWYq3GEbmaNgRnAECAPGG1meRHN/g+wwDnXCxgFPB/rjoqIz6Tx3p/x4mWE3hvY4Zz7CMDMioHhQGlYGwdcUPH4QmBvLDspIj4SzJurWmLMeQnoWcDusONy4KqINr8GlpvZfwDfBG6IdiIzKwQKAbKzs2vbVxFJdeGbUrTvq9F5jHm5KWpRnnMRx6OBOc65dsBQ4H/MrNK5nXMznXMFzrmC1q1b1763IpLawjeluPcNjc5jzEtALwcuCztuR+WUylhgAYBz7j2gKdAqFh0UEZ9RmiVuvAT0dUBHM8s1s28QuOm5KKLNJ8D1AGbWhUBAPxDLjoqISPVqzKE7506b2ThgGYEpibOcc1vM7CmgxDm3CPgl8Ecze4RAOuYe51xkWkZE0knkoiFQXZY48zQPvWJO+eKI5yaHPS4Fro1t10QkpQVnsoQHcNVliSst/ReR2NOioYRQQBeR2AhPsagmS0IooItI/UXOLw/OMddslgalgC4idRcclQdH5CqslVAK6CJSN9FWfSqYJ5QCuojUTfiqTwXypKCALiLehd/4VHGtpKMNLkTEu/ANKTSnPOlohC4iVYtc7RlcKKS55UlJI3QRqVrkFnEalSc1jdBFpHoakacMBXSRdBatgFY4FdNKKUq5iKSr4Dzy4KKgaJRiSSkaoYukK80j9x0FdJF0onnkvqaUi0g60TxyX9MIXSQdBEfmmkfuawroIn4XrYiW+JICuojf6eZn2lBAF/Ej3fxMSwroIn4RbQu49n118zONKKCL+EX4TU9tOJGWFNBFUk1Vy/U1gyXtaR66SKqJrIAYpNRK2tMIXSTZqSa5eKSALpJsIgN4+A1O0EhcqqSALpJswm9ugm5wimcK6CLJQsvzpZ4U0EUaQk0bScC5qRWlVKQOFNBFGkJkGiUapVaknjwFdDMbDDwHNAZecs49HaXNSODXgAM2OufujGE/RVKf0igSZzXOQzezxsAMYAiQB4w2s7yINh2BicC1zrmuwC/i0FeR1FQyu/pt3kRixMvCot7ADufcR865k0AxMDyizQPADOfcIQDn3Gex7aZICgvmzpUXlzjzEtCzgN1hx+UVz4XrBHQys7+b2eqKFE0lZlZoZiVmVnLgwIG69VgkFanaoTQALwHdojznIo4zgI7AAGA08JKZtaj0JudmOucKnHMFrVu3rm1fRUSkGl4CejlwWdhxO2BvlDYLnXOnnHM7ge0EAryIiDQQLwF9HdDRzHLN7BvAKGBRRJu/AgMBzKwVgRTMR7HsqIiIVK/GgO6cOw2MA5YBW4EFzrktZvaUmQ2raLYMOGhmpcAK4DHn3MF4dVpERCrzNA/dObcYWBzx3OSwxw54tOJHRCK3gKtuQZFIjGilqEgsBQO5toCTBFBAF4ml4BJ/LeOXBFBAF4kFVUqUJKCALlJfJbPhbxXVLlQpURJIAV2kvoI3P2+ZphSLJJQ2iRapj2DhLS3tlySgEbpIXUTOZlGaRZKAArpIXWg2iyQhBXSR2tBsFkliCugiXkRbMKQ0iyQZBXSRmkSblqgUiyQhBXQROLf2SqTgqFzTEiXJKaCLRI7AI2lULilCAV1EC4PEJ7SwSAS0MEh8QQFdRMQnFNAlvQWX7ov4gAK6pK/wm6GaUy4+oJuikn4iFwnpZqj4hAK6pI+qVnsqmItPKKBL+lBBLfE5BXRJLyqoJT6mgC7+FbmcP1ghUcSnFNDFPyIDeHiuHALBXLNZxMcU0MU/wuuUg3LlknYU0CV1VZVSUY5c0pQWFknqCo7Ig5RSkTSnEbqkNo3IRUI0QpfUUzIbZt987uhcRBTQJQWF3/xUikUkRCkXSS3B6ojt+yrVIhLB0wjdzAab2XYz22FmE6ppN8LMnJkVxK6LIhVUHVGkWjWO0M2sMTADGASUA+vMbJFzrjSiXXPgYWBNPDoqaSbaps2qjihSLS8pl97ADufcRwBmVgwMB0oj2v0X8FtgfEx7KP4ULWCHi1zlGXyshUIiVfIS0LOA3WHH5cBV4Q3MrBdwmXPub2ZWZUA3s0KgECA7O7v2vZXUVdOy/EgK3iK15iWgW5TnXOhFs0bAs8A9NZ3IOTcTmAlQUFDgamgufqJl+SJx5yWglwOXhR23A/aGHTcH8oF3zAzgUmCRmQ1zzpXEqqOSooIjcy3LF4k7LwF9HdDRzHKBPcAo4M7gi865w0Cr4LGZvQOMVzBPU9WlVjQzRSSuagzozrnTZjYOWAY0BmY557aY2VNAiXNuUbw7KUmspty4UisiDcbTwiLn3GJgccRzk6toO6D+3ZKUED4vXAFcJOG0UlTqJjyYa164SFJQQBdvqkqtKJiLJA0V5xJvImuPt++rYC6SZDRCF+807VAkqWmELiLiEwroIiI+oYAuIuITCuhSs+CmEiKS1BTQpWbB6Ypaui+S1DTLRaoWXlirfV9NURRJchqhS9W0GbNIStEIXaLTZswiKUcBXf4tfHl/8CaoRuYiKUMpF/m38OX9WtovknI0QpdzaXm/SMrSCF0CqZbZN59bfEtEUo5G6OksmDPXNnEivqCAno6qCuTKl4ukNAV0P4vclCJIgVzElxTQ/SjaCDycArmILymg+0FV28MpcIukFQV0Pwhfog8K5CJpSgHdLzR/XCTtKaCnmmg3OsNH5yKSthTQU0G0GivhNzpVDVFEUEBPDeE5cuXHRaQKCujJTmVsRcQj1XJJdtr+TUQ8UkBPBdr+TUQ8UMolGYXfBNUMFhHxyNMI3cwGm9l2M9thZhOivP6omZWa2SYze8vM2se+q2kkfKMJzWAREY9qHKGbWWNgBjAIKAfWmdki51xpWLN/AAXOuWNm9jPgt8AP49Fh39NNUBGpIy8pl97ADufcRwBmVgwMB0IB3Tm3Iqz9auCuWHbS97SXp4jEgJeUSxawO+y4vOK5qowFlkR7wcwKzazEzEoOHDjgvZd+p708RSQGvIzQLcpzLmpDs7uAAuC6aK8752YCMwEKCgqiniNtRLvxqRSLiNSDl4BeDlwWdtwO2BvZyMxuAJ4ArnPOnYhN93woWq1y3fgUkRjwEtDXAR3NLBfYA4wC7gxvYGa9gBeBwc65z2LeSz/Qtm8iEmc1BnTn3GkzGwcsAxoDs5xzW8zsKaDEObcIKALOB14xM4BPnHPD4tjv5KdNJ0SkgXlaWOScWwwsjnhuctjjG2Lcr9QSraRtZFVEBXIRiTOtFI2FyB2DQAFcRBqcAnp9aSGQiCQJFeeqL1VDFJEkoRF6XUTOIVc1RBFJAgroXlQ3Y0VzyEUkSSigexF501M3PEUkCSmgh4s2/RC0NF8S6tSpU5SXl/P1118nuivSgJo2bUq7du3IzMz0/B4F9HDRph+C0iqSUOXl5TRv3pycnBwqFu6JzznnOHjwIOXl5eTm5np+nwJ6JI3EJcl8/fXXCuZpxsxo2bIlta1Km54BvabUikiSUTBPP3X5ztNzHnp4/fFwSq2ISApLz4AO/06tRP5o5orIOb744guef/75Or136NChfPHFF7V+X48ePRg9evQ5zw0YMICSkpLQ8a5du8jPzw8dr127lv79+9O5c2e+853vcP/993Ps2DFPn7d06VI6d+5Mhw4dePrpp6O2+fjjj7n++uvp3r07AwYMoLy8PPTa448/Tn5+Pvn5+bz88suh599++22uuOIK8vPzGTNmDKdPnwbg8OHD3HrrrfTo0YOuXbsye/ZsT/2sSXoF9JLZMPvm6KNzEYmquoB+5syZat+7ePFiWrRoUavP27p1K2fPnmXlypV89dVXnt6zf/9+7rjjDqZOncr27dvZunUrgwcP5ssvv6zxvWfOnOGhhx5iyZIllJaWMn/+fEpLSyu1Gz9+PHfffTebNm1i8uTJTJw4EYA33niD999/nw0bNrBmzRqKioo4cuQIZ8+eZcyYMRQXF7N582bat2/P3LlzAZgxYwZ5eXls3LiRd955h1/+8pecPHmyFr9L0aVXDj18FotSK5KCnvx/WyjdeySm58xrewH/eWvXKl+fMGECH374IT179mTQoEHcfPPNPPnkk7Rp04YNGzZQWlrKbbfdxu7du/n666/5+c9/TmFhIQA5OTmUlJRw9OhRhgwZQt++fVm1ahVZWVksXLiQ8847r9Ln/fnPf+bHP/4xW7duZdGiRZVG6tHMmDGDMWPG0KdPHyCQfx4xwtvf8bVr19KhQwcuv/xyAEaNGsXChQvJy8s7p11paSnPPvssAAMHDuS2224LPX/dddeRkZFBRkYGPXr0YOnSpQwcOJAmTZrQqVMnAAYNGsSUKVMYO3YsZsaXX36Jc46jR49y8cUXk5FR/3Ds/xF6cFQeHJkHUy1KrYh48vTTT/Ptb3+bDRs2UFRUBASC4G9+85vQSHbWrFmsX7+ekpISpk+fzsGDByudp6ysjIceeogtW7bQokULXnvttaif9/LLL/PDH/6Q0aNHM3/+fE993Lx5M1deeWXU11asWEHPnj0r/VxzzTUA7Nmzh8su+/embO3atWPPnj2VztOjR49Qn19//XW+/PJLDh48SI8ePViyZAnHjh3j888/Z8WKFezevZtWrVpx6tSpUJro1VdfZffuwPbM48aNY+vWrbRt25Zu3brx3HPP0ahR/cOx/0fo4aNyjcwlxVU3km5IvXv3Pmd+9PTp03n99dcB2L17N2VlZbRs2fKc9+Tm5tKzZ08ArrzySnbt2lXpvOvWraN169a0b9+edu3acd9993Ho0CEuuuiiqLM+vMwEGThwIBs2bKjydecqb28c7bzPPPMM48aNY86cOfTv35+srCwyMjK48cYbWbduHddccw2tW7emT58+ZGRkYGYUFxfzyCOPcOLECW688cbQKHzZsmX07NmTt99+mw8//JBBgwbRr18/Lrjgghqvpzr+DugqbSsSF9/85jdDj9955x3efPNN3nvvPZo1a8aAAQOirmpt0qRJ6HHjxo05fvx4pTbz589n27Zt5OTkAHDkyBFee+017r//flq2bMmhQ4dCbf/1r3/RqlUrALp27cr69esZPnx4pXOuWLGCRx55pNLzzZo1Y9WqVbRr1y40cobAQq62bdtWat+2bVv+8pe/AHD06FFee+01LrzwQgCeeOIJnnjiCQDuvPNOOnbsCECfPn149913AVi+fDn//Oc/AZg9ezYTJkzAzOjQoQO5ubls27aN3r17V/rc2vBvyqVkNvztF4HHGpWL1Fnz5s2rvbl4+PBhLrroIpo1a8a2bdtYvXp1nT7n7NmzvPLKK2zatIldu3axa9cuFi5cGEq7DBgwgHnz5oVG1HPnzmXgwIFAIIUxd+5c1qxZEzrfvHnz2LdvX2iEHvmzatUqAL773e9SVlbGzp07OXnyJMXFxQwbVnkHzc8//5yzZ88CMGXKFO677z4gcFM1mGLatGkTmzZt4sYbbwTgs88CWyyfOHGCqVOn8tOf/hSA7Oxs3nrrLSBwQ3f79u2hHH59+DegBxcO3TJN+XKRemjZsiXXXnst+fn5PPbYY5VeHzx4MKdPn6Z79+5MmjSJq6++uk6fs3LlSrKyssjKygo9179/f0pLS/n0008pLCykefPm9OjRgx49enD06FHGjx8PwLe+9S2Ki4sZP348nTt3pkuXLrz77rueUhgZGRn8/ve/56abbqJLly6MHDmSrl0Dqa3JkyezaNEiIPA/kc6dO9OpUyf2798fGpGfOnWKfv36kZeXR2FhIfPmzQulVoqKiujSpQvdu3fn1ltv5Xvf+x4AkyZNYtWqVXTr1o3rr7+eqVOnhv63UR8WLX/UEAoKClz4nFKvfvjiewC8/JM+1TecfXPgV6VaJMVt3bqVLl26JLobkgDRvnszW++cK4jW3l859MiNJ7SMX0TSiL9SLuFL+jWjRUTSjL9G6KBqiSKStvwzQg9OURQRSVP+CejB3LnSLCKSpvwT0CGwgEhTFEUkTfkroItIzNWnfC7AtGnTqi1je+DAATIzM3nxxRfPef78888/53jOnDmMGzcudPynP/2J/Px8unbtSl5eHs8884znPk2ZMoUOHTrQuXNnli1bFrXNPffcEypX0LNnz1D5gG3bttGnTx+aNGlS6TOfffZZunbtSn5+PqNHjw6tmK3qXLGW+gFdJXFF4ireAf2VV17h6quv9lyIC2DJkiVMmzaN5cuXs2XLFt5///3QMvyalJaWUlxczJYtW1i6dCkPPvhglWWAi4qKQitLg3VoLr74YqZPnx5a1BS0Z88epk+fTklJCZs3b+bMmTMUFxdXe65YS/1ZLiqJK+lkyYTYD14u7QZDom/qAJXL5xYVFVFUVMSCBQs4ceIEt99+O08++SRfffUVI0eOpLy8nDNnzjBp0iT279/P3r17GThwIK1atWLFihWVzj9//nx+97vfceedd7Jnz55zVopWZcqUKTzzzDOhmitNmzblgQce8HS5CxcuZNSoUTRp0oTc3Fw6dOjA2rVrQ6V3a3LJJZdwySWX8MYblWfTnT59muPHj5OZmcmxY8ei1oSJp9QfoYNK4orEUWT53OXLl1NWVsbatWvZsGED69evZ+XKlSxdupS2bduyceNGNm/ezODBg3n44Ydp27YtK1asiBrMd+/ezb59++jduzcjR448Z7ef6lRXLreoqChqudyHH34Y8F4uFwJFt7p37x6qmFidrKwsxo8fT3Z2Nm3atOHCCy8M1XSp7bnqKvVH6CLppJqRdENZvnw5y5cvp1evXkCg8mBZWRn9+vVj/PjxPP7449xyyy3069evxnMVFxczcuRIILCxxNixY3n00UerbO+lXO5jjz0WteZMkNdyuVOmTOHSSy/l5MmTFBYWMnXqVCZPnlzleQ8dOsTChQvZuXMnLVq04I477mDevHncddddtT5XXXkaoZvZYDPbbmY7zGxClNebmNnLFa+vMbOcWHe0EuXORRLCOcfEiRND+eAdO3YwduxYOnXqxPr16+nWrRsTJ07kqaeeqvFc8+fPZ86cOeTk5DBs2DA2btxIWVkZAOedd94527JFK5cbTU0jdK/lctu0aYOZ0aRJE+69917Wrl1b7bW8+eab5Obm0rp1azIzM/n+978fquhY23PVVY0B3cwaAzOAIUAeMNrM8iKajQUOOec6AM8CU2Pd0UqUOxdpEJHlc2+66SZmzZrF0aNHgUAK47PPPmPv3r00a9aMu+66i/Hjx/P+++9HfX/Q9u3b+eqrr9izZ0+oXO7EiRNDNxKvu+465s2bB8Dx48dZsGBBqFzuxIkT+dWvfsW+ffuAQHna6dOnA4ERerRyucHXhw0bRnFxMSdOnGDnzp2UlZVFrUP+6aefAoF/wP7617+esyF1NNnZ2axevZpjx47hnOOtt94KFdaq7bnqykvKpTewwzn3EYCZFQPDgfBdVIcDv654/CrwezMzF4dSjmMOv0D70x+CfaJl/iINILx87pAhQygqKmLr1q2hm4jnn38+8+bNY8eOHTz22GM0atSIzMxM/vCHPwBQWFjIkCFDaNOmzTl59Pnz53P77bef81k/+MEPGDVqFJMmTeK5557jJz/5CdOnT8c5x913303//v0BGDp0KPv37+eGG27AOYeZheqT16Rr166MHDmSvLw8MjIymDFjBo0bNw6d96WXXqJt27b86Ec/4sCBAzjn6NmzJy+88AIA+/bto6CggCNHjtCoUSOmTZtGaWkpV111FSNGjOCKK64gIyODXr16hfZWrepcsVZj+VwzGwEMds7dX3H8Y+Aq59y4sDabK9qUVxx/WNHm84hzFQKFANnZ2Vd+/PHHte7w6ucf4NJjZeS0/GZgZK4boeJzKp+bvuJRPjfaXYjIfwW8tME5NxOYCYF66B4+u5KrH/xjXd4mIuJ7Xm6KlgOXhR23A/ZW1cbMMoALgX/FooMiIuKNl4C+DuhoZrlm9g1gFLAoos0iYEzF4xHA2/HIn4ukK/11Sj91+c5rDOjOudPAOGAZsBVY4JzbYmZPmVlwJ9X/C7Q0sx3Ao0ClqY0iUjdNmzbl4MGDCuppxDnHwYMHadq0aa3el3J7ioqkm1OnTlFeXh4q9CTpoWnTprRr147MzMxznk+fPUVFfCgzM5Pc3NxEd0NSgD9quYiIiAK6iIhfKKCLiPhEwm6KmtkBoPZLRQNaAZ/X2MpfdM3pQdecHupzze2dc62jvZCwgF4fZlZS1V1ev9I1pwddc3qI1zUr5SIi4hMK6CIiPpGqAX1mojuQALrm9KBrTg9xueaUzKGLiEhlqTpCFxGRCAroIiI+kdQBPSk3p44zD9f8qJmVmtkmM3vLzNonop+xVNM1h7UbYWbOzFJ+ipuXazazkRXf9RYz+3ND9zHWPPzZzjazFWb2j4o/30MT0c9YMbNZZvZZxY5u0V43M5te8fuxycyuqPeHOueS8gdoDHwIXA58A9gI5EW0eRB4oeLxKODlRPe7Aa55INCs4vHP0uGaK9o1B1YCq4GCRPe7Ab7njsA/gIsqji9JdL8b4JpnAj+reJwH7Ep0v+t5zf2BK4DNVbw+FFhCYMe3q4E19f3MZB6hhzands6dBIKbU4cbDsytePwqcL2ZRdsOL1XUeM3OuRXOuWMVh6sJ7CCVyrx8zwD/BfwW8EMNWS/X/AAwwzl3CMA591kD9zHWvFyzAy6oeHwhlXdGSynOuZVUv3PbcOBPLmA10MLM2tTnM5M5oGcBu8OOyyuei9rGBTbiOAy0bJDexYeXaw43lsC/8Kmsxms2s17AZc65vzVkx+LIy/fcCehkZn83s9VmNrjBehcfXq7518BdZlYOLAb+o2G6ljC1/fteo2Suhx6zzalTiOfrMbO7gALgurj2KP6qvWYzawQ8C9zTUB1qAF6+5wwCaZcBBP4X9q6Z5Tvnvohz3+LFyzWPBuY4535nZn2A/6m45rPx715CxDx+JfMIPR03p/ZyzZjZDcATwDDn3IkG6lu81HTNzYF84B0z20Ug17goxW+Mev2zvdA5d8o5txPYTiDApyov1zwWWADgnHsPaEqgiJVfefr7XhvJHNDTcXPqGq+5Iv3wIoFgnup5Vajhmp1zh51zrZxzOc65HAL3DYY551J5/0Ivf7b/SuAGOGbWikAK5qMG7WVsebnmT4DrAcysC4GAfqBBe9mwFgF3V8x2uRo47Jz7tF5nTPSd4BruEg8F/kng7vgTFc89ReAvNAS+8FeAHcBa4PJE97kBrvlNYD+woeJnUaL7HO9rjmj7Dik+y8Xj92zAfwOlwAfAqET3uQGuOQ/4O4EZMBuAGxPd53pe73zgU+AUgdH4WOCnwE/DvuMZFb8fH8Tiz7WW/ouI+EQyp1xERKQWFNBFRHxCAV1ExCcU0EVEfEIBXUTEJxTQRUR8QgFdRMQn/j+C1SKF8i21tgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "proba = new_lr_cls.predict_proba(train_features)[:, 1]\n",
    "auc = roc_auc_score(y_train, proba)\n",
    "plt.plot(*roc_curve(y_train, proba)[:2], label='%s AUC=%.4f' % ('train', auc))\n",
    "\n",
    "proba = new_lr_cls.predict_proba(test_features)[:, 1]\n",
    "auc = roc_auc_score(y_test, proba)\n",
    "plt.plot(*roc_curve(y_test, proba)[:2], label='%s AUC=%.4f' % ('test', auc))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
